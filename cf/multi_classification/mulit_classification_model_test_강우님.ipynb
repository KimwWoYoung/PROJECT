{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url\n",
    "https://www.kaggle.com/datasets/uciml/faulty-steel-plates\n",
    "\n",
    "데이터 정보\n",
    "독립변수\n",
    "- X_Minimum: 결함 주변 경계 상자의 최소 x 좌표입니다.\n",
    "- X_Maximum: 결함 주변 경계 상자의 최대 x 좌표입니다.\n",
    "- Y_Minimum: 결함 주변 경계 상자의 최소 y 좌표입니다.\n",
    "- Y_Maximum: 결함 주변 경계 상자의 최대 y 좌표입니다.\n",
    "- Pixels_Areas: 결함 내의 총 픽셀 수입니다.\n",
    "- X_Perimeter: 결함의 x 축 주변 둘레입니다.\n",
    "- Y_Perimeter: 결함의 y 축 주변 둘레입니다.\n",
    "- Sum_of_Luminosity: 결함 영역의 총 빛의 합계입니다.\n",
    "- Minimum_of_Luminosity: 결함 영역의 최소 빛 강도입니다.\n",
    "- Maximum_of_Luminosity: 결함 영역의 최대 빛 강도입니다.\n",
    "- Length_of_Conveyer: 컨베이어의 길이입니다.\n",
    "- TypeOfSteel_A300: 강철 유형 중 A300인지 여부를 나타냅니다.\n",
    "- TypeOfSteel_A400: 강철 유형 중 A400인지 여부를 나타냅니다.\n",
    "- Steel_Plate_Thickness: 강판의 두께입니다.\n",
    "- Edges_Index: 가장자리 지수입니다.\n",
    "- Empty_Index: 빈 영역 지수입니다.\n",
    "- Square_Index: 사각형 지수입니다.\n",
    "- Outside_X_Index: X축 외부 지수입니다.\n",
    "- Edges_X_Index: X축 가장자리 지수입니다.\n",
    "- Edges_Y_Index: Y축 가장자리 지수입니다.\n",
    "- Outside_Global_Index: 전체 외부 지수입니다.\n",
    "- LogOfAreas: 결함 영역의 면적의 로그값입니다.\n",
    "- Log_X_Index: X축 로그 지수입니다.\n",
    "- Log_Y_Index: Y축 로그 지수입니다.\n",
    "- Orientation_Index: 방향 지수입니다.\n",
    "- Luminosity_Index: 빛의 강도 지수입니다.\n",
    "- SigmoidOfAreas: 결함 영역의 로지스틱값입니다.\n",
    "\n",
    "종속변수\n",
    "- Pastry: 패스트리 결함의 여부를 나타냅니다.\n",
    "- Z_Scratch: Z 스크래치 결함의 여부를 나타냅니다.\n",
    "- K_Scatch: K 스크래치 결함의 여부를 나타냅니다.\n",
    "- Stains: 얼룩 결함의 여부를 나타냅니다.\n",
    "- Dirtiness: 더러움 결함의 여부를 나타냅니다.\n",
    "- Bumps: 덩어리 결함의 여부를 나타냅니다.\n",
    "- Other_Faults: 기타 결함의 여부를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install -U scikit-learn\n",
    "# pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = \"./data/\"\n",
    "file_name = \"mulit_classification_data.csv\"\n",
    "df = pd.read_csv(route+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"mulit_classification_data_engineering.csv\"\n",
    "# df_eda = pd.read_csv(route+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>...</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>270900</td>\n",
       "      <td>270944</td>\n",
       "      <td>267</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>24220</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0         42         50     270900     270944           267           17   \n",
       "1        645        651    2538079    2538108           108           10   \n",
       "2        829        835    1553913    1553931            71            8   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           44              24220                     76   \n",
       "1           30              11397                     84   \n",
       "2           19               7972                     99   \n",
       "\n",
       "   Maximum_of_Luminosity  ...  Orientation_Index  Luminosity_Index  \\\n",
       "0                    108  ...             0.8182           -0.2913   \n",
       "1                    123  ...             0.7931           -0.1756   \n",
       "2                    125  ...             0.6667           -0.1228   \n",
       "\n",
       "   SigmoidOfAreas  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  \\\n",
       "0          0.5822       1          0         0       0          0      0   \n",
       "1          0.2984       1          0         0       0          0      0   \n",
       "2          0.2150       1          0         0       0          0      0   \n",
       "\n",
       "   Other_Faults  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>...</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>386779</td>\n",
       "      <td>386794</td>\n",
       "      <td>292</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>37572</td>\n",
       "      <td>120</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4828</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>137</td>\n",
       "      <td>170</td>\n",
       "      <td>422497</td>\n",
       "      <td>422528</td>\n",
       "      <td>419</td>\n",
       "      <td>97</td>\n",
       "      <td>47</td>\n",
       "      <td>52715</td>\n",
       "      <td>117</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0606</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1261</td>\n",
       "      <td>1281</td>\n",
       "      <td>87951</td>\n",
       "      <td>87967</td>\n",
       "      <td>103</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>11682</td>\n",
       "      <td>101</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.1139</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "1938        145        174     386779     386794           292           40   \n",
       "1939        137        170     422497     422528           419           97   \n",
       "1940       1261       1281      87951      87967           103           26   \n",
       "\n",
       "      Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "1938           22              37572                    120   \n",
       "1939           47              52715                    117   \n",
       "1940           22              11682                    101   \n",
       "\n",
       "      Maximum_of_Luminosity  ...  Orientation_Index  Luminosity_Index  \\\n",
       "1938                    140  ...            -0.4828            0.0052   \n",
       "1939                    140  ...            -0.0606           -0.0171   \n",
       "1940                    133  ...            -0.2000           -0.1139   \n",
       "\n",
       "      SigmoidOfAreas  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  \\\n",
       "1938          0.7079       0          0         0       0          0      0   \n",
       "1939          0.9919       0          0         0       0          0      0   \n",
       "1940          0.5296       0          0         0       0          0      0   \n",
       "\n",
       "      Other_Faults  \n",
       "1938             1  \n",
       "1939             1  \n",
       "1940             1  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(3), df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 X와 y로 나누기\n",
    "X = df.iloc[:,  0:27]    # 독립변수 (1열부터 27열까지)\n",
    "y = df.iloc[:, 27:  ]    # 종속변수 (28열부터 34열까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(X.head(3), X.tail(3))\n",
    "# display(y.head(3), y.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train과 y_test를 1차원 배열로 변환\n",
    "y_train = y_train.values.argmax(axis=1)\n",
    "y_test = y_test.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=7000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=7000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=7000, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression 모델 생성 및 학습\n",
    "model = LogisticRegression(max_iter=7000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트로 예측 수행\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다중 분류 정확도: 0.5398457583547558\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"다중 분류 정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다중 분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        29\n",
      "           1       0.32      0.29      0.30        41\n",
      "           2       0.94      0.75      0.83        83\n",
      "           3       0.57      0.92      0.71        13\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.56      0.25      0.35        72\n",
      "           6       0.46      0.74      0.57       143\n",
      "\n",
      "    accuracy                           0.54       389\n",
      "   macro avg       0.41      0.42      0.39       389\n",
      "weighted avg       0.52      0.54      0.51       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khan\\anaconda3\\envs\\sec6_pj1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\khan\\anaconda3\\envs\\sec6_pj1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\khan\\anaconda3\\envs\\sec6_pj1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 보고서 출력\n",
    "print(\"다중 분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 파이프라인 생성: 데이터 스케일링 -> 로지스틱 회귀\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           SGDClassifier(loss='log_loss', \n",
    "                                         max_iter=7000, \n",
    "                                         learning_rate='constant', \n",
    "                                         eta0=0.001, \n",
    "                                         random_state=42, \n",
    "                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 예측\n",
    "model_pipe.fit(X_train, y_train)\n",
    "y_pipe_pred = model_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 다중 분류 정확도: 0.7010309278350515\n",
      "Train Dataset log loss 점수: 0.894154897518892\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 정확도 평가\n",
    "accuracy = model_pipe.score(X_train, y_train)\n",
    "\n",
    "# 테스트 세트의 log loss 점수 계산\n",
    "y_pipe_prob = model_pipe.predict_proba(X_train)\n",
    "log_loss_score = log_loss(y_train, y_pipe_prob)\n",
    "\n",
    "print(\"Train 다중 분류 정확도:\", accuracy)\n",
    "print(\"Train Dataset log loss 점수:\", log_loss_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 다른 loss 확인용\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pipe_pred_sample = model_pipe.predict(X_train)\n",
    "\n",
    "# # Huber loss를 계산\n",
    "# loss = mean_squared_error(y_train, y_pipe_pred_sample, squared=False)\n",
    "\n",
    "# print(\"다중 분류 Huber Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 다중 분류 정확도: 0.7223650385604113\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pipe_pred)\n",
    "print(\"Test 다중 분류 정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다중 분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.52      0.54        29\n",
      "           1       0.73      0.85      0.79        41\n",
      "           2       0.94      0.95      0.95        83\n",
      "           3       0.92      0.85      0.88        13\n",
      "           4       1.00      0.12      0.22         8\n",
      "           5       0.58      0.58      0.58        72\n",
      "           6       0.68      0.69      0.68       143\n",
      "\n",
      "    accuracy                           0.72       389\n",
      "   macro avg       0.77      0.65      0.66       389\n",
      "weighted avg       0.73      0.72      0.72       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 보고서 출력\n",
    "print(\"다중 분류 보고서:\")\n",
    "print(classification_report(y_test, y_pipe_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n",
       "0          1          0         0       0          0      0             0\n",
       "1          1          0         0       0          0      0             0\n",
       "2          1          0         0       0          0      0             0\n",
       "3          1          0         0       0          0      0             0\n",
       "4          1          0         0       0          0      0             0\n",
       "...      ...        ...       ...     ...        ...    ...           ...\n",
       "1936       0          0         0       0          0      0             1\n",
       "1937       0          0         0       0          0      0             1\n",
       "1938       0          0         0       0          0      0             1\n",
       "1939       0          0         0       0          0      0             1\n",
       "1940       0          0         0       0          0      0             1\n",
       "\n",
       "[1941 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 - 표준화 (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_sample = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01648138, -1.14163891, -0.77772863, ...,  1.46765551,\n",
       "        -1.0757517 , -0.00948966],\n",
       "       [ 0.14189427,  0.06640322,  0.50018799, ...,  1.4175296 ,\n",
       "        -0.2978242 , -0.845759  ],\n",
       "       [ 0.49536213,  0.43625306, -0.05454637, ...,  1.16510269,\n",
       "         0.05718506, -1.09151256],\n",
       "       ...,\n",
       "       [-0.81861622, -0.89239228, -0.71241235, ..., -1.13050437,\n",
       "         0.91781358,  0.3609087 ],\n",
       "       [-0.83398438, -0.9004325 , -0.69227956, ..., -0.28735056,\n",
       "         0.76787595,  1.19776737],\n",
       "       [ 1.32524319,  1.3327369 , -0.88084954, ..., -0.5657391 ,\n",
       "         0.11702564, -0.16448532]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 은닉층 추가\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "\n",
    "    # 출력층 추가 - 다중 레이블 문제를 위해 활성화 함수를 'sigmoid'로 변경\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일 - 손실 함수를 'binary_crossentropy'로 변경\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_mlp(X, y):\n",
    "    # 데이터 전처리 - 표준화 (Standardization)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 데이터 분할 - 학습 데이터와 테스트 데이터로 분할합니다.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # MLP 모델 생성\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    num_classes = y_train.shape[1]  # 다중 레이블 문제이므로 y_train.shape[1]은 7입니다.\n",
    "    model = build_mlp_model(input_shape, num_classes)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "    # 예측\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # 성능 평가 - classification_report를 사용하여 클래스별 정밀도, 재현율, F1-score를 출력\n",
    "    print(\"분류 결과 보고서:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.4534 - val_loss: 0.2844 - val_accuracy: 0.5385\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.5888 - val_loss: 0.2288 - val_accuracy: 0.6346\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.6669 - val_loss: 0.1982 - val_accuracy: 0.7115\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.7264 - val_loss: 0.1848 - val_accuracy: 0.7244\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.7357 - val_loss: 0.1845 - val_accuracy: 0.7179\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.7579 - val_loss: 0.1687 - val_accuracy: 0.7372\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.7622 - val_loss: 0.1683 - val_accuracy: 0.7564\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.7715 - val_loss: 0.1661 - val_accuracy: 0.7628\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.7772 - val_loss: 0.1719 - val_accuracy: 0.7628\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.7837 - val_loss: 0.1754 - val_accuracy: 0.7564\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.7844 - val_loss: 0.1639 - val_accuracy: 0.7692\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.7894 - val_loss: 0.1689 - val_accuracy: 0.7756\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.7980 - val_loss: 0.1795 - val_accuracy: 0.7756\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.8044 - val_loss: 0.1690 - val_accuracy: 0.7628\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.8080 - val_loss: 0.1694 - val_accuracy: 0.7692\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.8059 - val_loss: 0.1800 - val_accuracy: 0.7564\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.8102 - val_loss: 0.1749 - val_accuracy: 0.7628\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.8188 - val_loss: 0.1760 - val_accuracy: 0.7692\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.8223 - val_loss: 0.1723 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.8245 - val_loss: 0.1815 - val_accuracy: 0.7628\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.8331 - val_loss: 0.1740 - val_accuracy: 0.7564\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.8181 - val_loss: 0.1627 - val_accuracy: 0.7885\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.8360 - val_loss: 0.1779 - val_accuracy: 0.7436\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.8410 - val_loss: 0.1949 - val_accuracy: 0.7692\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.8338 - val_loss: 0.1711 - val_accuracy: 0.7885\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.8481 - val_loss: 0.1792 - val_accuracy: 0.7756\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.8474 - val_loss: 0.1672 - val_accuracy: 0.7885\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.8481 - val_loss: 0.1726 - val_accuracy: 0.7756\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.8503 - val_loss: 0.1782 - val_accuracy: 0.7821\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.8560 - val_loss: 0.1727 - val_accuracy: 0.7692\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.8524 - val_loss: 0.1803 - val_accuracy: 0.7756\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.8603 - val_loss: 0.1812 - val_accuracy: 0.7821\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.8703 - val_loss: 0.1871 - val_accuracy: 0.7692\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.8560 - val_loss: 0.1642 - val_accuracy: 0.7885\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.8668 - val_loss: 0.1586 - val_accuracy: 0.7692\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.8761 - val_loss: 0.1667 - val_accuracy: 0.7949\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.8861 - val_loss: 0.1762 - val_accuracy: 0.7756\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.8818 - val_loss: 0.1695 - val_accuracy: 0.7821\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.8861 - val_loss: 0.1632 - val_accuracy: 0.7756\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.8868 - val_loss: 0.1834 - val_accuracy: 0.7756\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.8868 - val_loss: 0.1683 - val_accuracy: 0.8077\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.8861 - val_loss: 0.1747 - val_accuracy: 0.7564\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.8954 - val_loss: 0.1649 - val_accuracy: 0.7756\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.8947 - val_loss: 0.1578 - val_accuracy: 0.7885\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9019 - val_loss: 0.1541 - val_accuracy: 0.8013\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.8968 - val_loss: 0.1617 - val_accuracy: 0.7885\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9033 - val_loss: 0.1553 - val_accuracy: 0.7821\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9069 - val_loss: 0.1626 - val_accuracy: 0.8013\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9040 - val_loss: 0.1666 - val_accuracy: 0.7628\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9112 - val_loss: 0.1476 - val_accuracy: 0.8205\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "분류 결과 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51        29\n",
      "           1       0.85      0.85      0.85        41\n",
      "           2       0.96      0.96      0.96        83\n",
      "           3       0.92      0.92      0.92        13\n",
      "           4       0.60      0.75      0.67         8\n",
      "           5       0.62      0.57      0.59        72\n",
      "           6       0.71      0.64      0.68       143\n",
      "\n",
      "   micro avg       0.76      0.72      0.74       389\n",
      "   macro avg       0.74      0.74      0.74       389\n",
      "weighted avg       0.76      0.72      0.74       389\n",
      " samples avg       0.71      0.72      0.71       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khan\\anaconda3\\envs\\sec6_pj1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "X_test_sample = df.drop(columns=target_columns)\n",
    "y_test_sample = df[target_columns]\n",
    "\n",
    "# MLP 모델 학습 및 평가\n",
    "train_and_evaluate_mlp(X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.4154 - accuracy: 0.4721 - val_loss: 0.2829 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.5996 - val_loss: 0.2311 - val_accuracy: 0.6795\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.6941 - val_loss: 0.1994 - val_accuracy: 0.7115\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.7342 - val_loss: 0.1837 - val_accuracy: 0.7564\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.7357 - val_loss: 0.1755 - val_accuracy: 0.7308\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.7536 - val_loss: 0.1739 - val_accuracy: 0.7436\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.7679 - val_loss: 0.1690 - val_accuracy: 0.7372\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.7658 - val_loss: 0.1721 - val_accuracy: 0.7372\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.7679 - val_loss: 0.1728 - val_accuracy: 0.7372\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.7822 - val_loss: 0.1691 - val_accuracy: 0.7564\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.7894 - val_loss: 0.1676 - val_accuracy: 0.7692\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.7966 - val_loss: 0.1709 - val_accuracy: 0.7628\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.7966 - val_loss: 0.1741 - val_accuracy: 0.7436\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.8030 - val_loss: 0.1625 - val_accuracy: 0.7628\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.8080 - val_loss: 0.1637 - val_accuracy: 0.7628\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.8152 - val_loss: 0.1697 - val_accuracy: 0.7564\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.8173 - val_loss: 0.1676 - val_accuracy: 0.7500\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.8202 - val_loss: 0.1812 - val_accuracy: 0.7308\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.8266 - val_loss: 0.1594 - val_accuracy: 0.7628\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.8302 - val_loss: 0.1652 - val_accuracy: 0.7756\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.8324 - val_loss: 0.1645 - val_accuracy: 0.7756\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.8417 - val_loss: 0.1632 - val_accuracy: 0.7692\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.8352 - val_loss: 0.1630 - val_accuracy: 0.7949\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.8460 - val_loss: 0.1620 - val_accuracy: 0.7628\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.8503 - val_loss: 0.1702 - val_accuracy: 0.7821\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.8517 - val_loss: 0.1728 - val_accuracy: 0.7692\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.8546 - val_loss: 0.1627 - val_accuracy: 0.7885\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.8603 - val_loss: 0.1693 - val_accuracy: 0.8013\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.8574 - val_loss: 0.1805 - val_accuracy: 0.7885\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.8582 - val_loss: 0.1804 - val_accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.8689 - val_loss: 0.1719 - val_accuracy: 0.8013\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.8739 - val_loss: 0.1742 - val_accuracy: 0.7821\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.8639 - val_loss: 0.1726 - val_accuracy: 0.8013\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.8725 - val_loss: 0.1769 - val_accuracy: 0.8013\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.8804 - val_loss: 0.1828 - val_accuracy: 0.7949\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.8811 - val_loss: 0.1796 - val_accuracy: 0.7885\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.8775 - val_loss: 0.1795 - val_accuracy: 0.7949\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.8782 - val_loss: 0.1746 - val_accuracy: 0.8077\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.8897 - val_loss: 0.1749 - val_accuracy: 0.7949\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.8840 - val_loss: 0.1840 - val_accuracy: 0.8077\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.8883 - val_loss: 0.1710 - val_accuracy: 0.7885\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.8976 - val_loss: 0.1809 - val_accuracy: 0.7949\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.8961 - val_loss: 0.1937 - val_accuracy: 0.7821\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.8933 - val_loss: 0.1854 - val_accuracy: 0.7885\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.8983 - val_loss: 0.1966 - val_accuracy: 0.7885\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.8968 - val_loss: 0.1880 - val_accuracy: 0.7885\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9033 - val_loss: 0.1908 - val_accuracy: 0.7756\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9019 - val_loss: 0.1868 - val_accuracy: 0.8013\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9047 - val_loss: 0.1985 - val_accuracy: 0.8077\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9140 - val_loss: 0.1847 - val_accuracy: 0.7949\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "분류 결과 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50        29\n",
      "           1       0.85      0.83      0.84        41\n",
      "           2       0.95      0.96      0.96        83\n",
      "           3       0.92      0.85      0.88        13\n",
      "           4       0.60      0.75      0.67         8\n",
      "           5       0.59      0.56      0.57        72\n",
      "           6       0.73      0.69      0.71       143\n",
      "\n",
      "   micro avg       0.76      0.72      0.74       389\n",
      "   macro avg       0.74      0.73      0.73       389\n",
      "weighted avg       0.75      0.72      0.74       389\n",
      " samples avg       0.71      0.72      0.71       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khan\\anaconda3\\envs\\sec6_pj1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "X_test_sample = df_eda.drop(columns=target_columns)\n",
    "y_test_sample = df_eda[target_columns]\n",
    "\n",
    "# MLP 모델 학습 및 평가\n",
    "train_and_evaluate_mlp(X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n",
       "0          1          0         0       0          0      0             0\n",
       "1          1          0         0       0          0      0             0\n",
       "2          1          0         0       0          0      0             0\n",
       "3          1          0         0       0          0      0             0\n",
       "4          1          0         0       0          0      0             0\n",
       "...      ...        ...       ...     ...        ...    ...           ...\n",
       "1936       0          0         0       0          0      0             1\n",
       "1937       0          0         0       0          0      0             1\n",
       "1938       0          0         0       0          0      0             1\n",
       "1939       0          0         0       0          0      0             1\n",
       "1940       0          0         0       0          0      0             1\n",
       "\n",
       "[1941 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    # StandardScaler를 사용하여 특성 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # 레이블을 숫자로 인코딩 후 0부터 시작하는 인덱스로 변환\n",
    "    # label_encoder = LabelEncoder()\n",
    "    # y_encoded = label_encoder.fit_transform(y)\n",
    "    label_encoding = {\n",
    "        'Other_Faults': 0,\n",
    "        'Bumps': 1,\n",
    "        'K_Scatch': 2,\n",
    "        'Z_Scratch': 3,\n",
    "        'Pastry': 4,\n",
    "        'Stains': 5,\n",
    "        'Dirtiness': 6\n",
    "    }\n",
    "\n",
    "    # 새로운 어레이에 라벨 인코딩 값을 저장\n",
    "    y_encoded = y.apply(lambda row: label_encoding[y.columns[row.to_numpy().nonzero()[0][0]]], axis=1).values\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터로 분리\n",
    "    X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train_encoded, y_test_encoded\n",
    "\n",
    "\n",
    "def train_and_evaluate_svm(X_train, X_test, y_train_bin, y_test_bin):\n",
    "    # SVM 모델 생성\n",
    "    model = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train_bin)\n",
    "\n",
    "    # 예측\n",
    "    y_pred_bin = model.predict(X_test)\n",
    "\n",
    "    # 다중 레이블 문제에서의 정확도 평가\n",
    "    accuracy = accuracy_score(y_test_bin, y_pred_bin)\n",
    "    print(\"정확도:\", accuracy)\n",
    "\n",
    "    # 다중 레이블 문제에서의 오차 행렬\n",
    "    ml_cm = multilabel_confusion_matrix(y_test_bin, y_pred_bin)\n",
    "    for label, cm in zip(model.classes_, ml_cm):\n",
    "        print(f\"Label: {label}\")\n",
    "        print(cm)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7506426735218509\n",
      "Label: 0\n",
      "[[202  44]\n",
      " [ 41 102]]\n",
      "Label: 1\n",
      "[[288  29]\n",
      " [ 27  45]]\n",
      "Label: 2\n",
      "[[303   3]\n",
      " [  5  78]]\n",
      "Label: 3\n",
      "[[342   6]\n",
      " [  6  35]]\n",
      "Label: 4\n",
      "[[347  13]\n",
      " [ 12  17]]\n",
      "Label: 5\n",
      "[[376   0]\n",
      " [  1  12]]\n",
      "Label: 6\n",
      "[[379   2]\n",
      " [  5   3]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 X와 y로 나누기\n",
    "X = df.drop(columns=target_columns)\n",
    "y = df[target_columns]\n",
    "\n",
    "# 데이터 전처리\n",
    "X_train, X_test, y_train_bin, y_test_bin = preprocess_data(X, y)\n",
    "\n",
    "# SVM 모델 학습 및 평가\n",
    "svm_model = train_and_evaluate_svm(X_train, X_test, y_train_bin, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7583547557840618\n",
      "Label: 0\n",
      "[[203  43]\n",
      " [ 38 105]]\n",
      "Label: 1\n",
      "[[288  29]\n",
      " [ 27  45]]\n",
      "Label: 2\n",
      "[[303   3]\n",
      " [  4  79]]\n",
      "Label: 3\n",
      "[[342   6]\n",
      " [  6  35]]\n",
      "Label: 4\n",
      "[[349  11]\n",
      " [ 12  17]]\n",
      "Label: 5\n",
      "[[376   0]\n",
      " [  1  12]]\n",
      "Label: 6\n",
      "[[379   2]\n",
      " [  6   2]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 X와 y로 나누기\n",
    "X_eda = df_eda.drop(columns=target_columns)\n",
    "y_eda = df_eda[target_columns]\n",
    "\n",
    "# 데이터 전처리\n",
    "X_train, X_test, y_train_bin, y_test_bin = preprocess_data(X_eda, y_eda)\n",
    "\n",
    "# SVM 모델 학습 및 평가\n",
    "svm_model = train_and_evaluate_svm(X_train, X_test, y_train_bin, y_test_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 신경망(RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def load_data(data):\n",
    "    target_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "    X = data.drop(columns=target_columns)\n",
    "    y = data[target_columns]\n",
    "    # 데이터 정규화\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 분리\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1552, 1, 27)\n",
      "X_test shape: (389, 1, 27)\n",
      "y_train shape: (1552, 7)\n",
      "y_test shape: (389, 7)\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 4s 30ms/step - loss: 1.7508 - accuracy: 0.4327 - val_loss: 1.4914 - val_accuracy: 0.4984\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.4089 - accuracy: 0.4851 - val_loss: 1.2262 - val_accuracy: 0.5305\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.1892 - accuracy: 0.5576 - val_loss: 1.0151 - val_accuracy: 0.6367\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.9877 - accuracy: 0.6495 - val_loss: 0.8682 - val_accuracy: 0.6849\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.8651 - accuracy: 0.6704 - val_loss: 0.7871 - val_accuracy: 0.7170\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.8072 - accuracy: 0.7019 - val_loss: 0.7491 - val_accuracy: 0.7395\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7622 - accuracy: 0.7083 - val_loss: 0.7345 - val_accuracy: 0.7299\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.7139 - val_loss: 0.7159 - val_accuracy: 0.7331\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7069 - accuracy: 0.7309 - val_loss: 0.6914 - val_accuracy: 0.7299\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.7454 - val_loss: 0.6768 - val_accuracy: 0.7460\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6597 - accuracy: 0.7518 - val_loss: 0.6604 - val_accuracy: 0.7524\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.7550 - val_loss: 0.6500 - val_accuracy: 0.7524\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6283 - accuracy: 0.7607 - val_loss: 0.6417 - val_accuracy: 0.7492\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.7639 - val_loss: 0.6373 - val_accuracy: 0.7460\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.7728 - val_loss: 0.6308 - val_accuracy: 0.7653\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5847 - accuracy: 0.7736 - val_loss: 0.6240 - val_accuracy: 0.7492\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5773 - accuracy: 0.7768 - val_loss: 0.6169 - val_accuracy: 0.7524\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5652 - accuracy: 0.7824 - val_loss: 0.6111 - val_accuracy: 0.7621\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5666 - accuracy: 0.7865 - val_loss: 0.6091 - val_accuracy: 0.7717\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.7929 - val_loss: 0.6001 - val_accuracy: 0.7556\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.7905 - val_loss: 0.6096 - val_accuracy: 0.7556\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7929 - val_loss: 0.6076 - val_accuracy: 0.7621\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7961 - val_loss: 0.6006 - val_accuracy: 0.7685\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7994 - val_loss: 0.6029 - val_accuracy: 0.7524\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7961 - val_loss: 0.5897 - val_accuracy: 0.7717\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.8002 - val_loss: 0.5896 - val_accuracy: 0.7685\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.8042 - val_loss: 0.6045 - val_accuracy: 0.7717\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.8139 - val_loss: 0.5913 - val_accuracy: 0.7588\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.8082 - val_loss: 0.5897 - val_accuracy: 0.7749\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.8171 - val_loss: 0.5920 - val_accuracy: 0.7717\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.8139 - val_loss: 0.5852 - val_accuracy: 0.7717\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4815 - accuracy: 0.8131 - val_loss: 0.5801 - val_accuracy: 0.7781\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.8122 - val_loss: 0.5863 - val_accuracy: 0.7685\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8243 - val_loss: 0.5876 - val_accuracy: 0.7588\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.8219 - val_loss: 0.5700 - val_accuracy: 0.7781\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8098 - val_loss: 0.5983 - val_accuracy: 0.7653\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8122 - val_loss: 0.5716 - val_accuracy: 0.7653\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.8308 - val_loss: 0.5829 - val_accuracy: 0.7717\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8300 - val_loss: 0.5716 - val_accuracy: 0.7749\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8388 - val_loss: 0.5826 - val_accuracy: 0.7717\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8396 - val_loss: 0.5913 - val_accuracy: 0.7621\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8324 - val_loss: 0.5742 - val_accuracy: 0.7653\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.8276 - val_loss: 0.5819 - val_accuracy: 0.7685\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8477 - val_loss: 0.5774 - val_accuracy: 0.7717\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8453 - val_loss: 0.6017 - val_accuracy: 0.7717\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8485 - val_loss: 0.5887 - val_accuracy: 0.7717\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8445 - val_loss: 0.5874 - val_accuracy: 0.7717\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8477 - val_loss: 0.5932 - val_accuracy: 0.7814\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8477 - val_loss: 0.5777 - val_accuracy: 0.7685\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8517 - val_loss: 0.5806 - val_accuracy: 0.7749\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7661\n",
      "Test loss: 0.6470, Test accuracy: 0.7661\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 데이터 전처리\n",
    "    X_train, X_test, y_train, y_test, scaler = load_data(df)\n",
    "\n",
    "    # time steps 설정\n",
    "    time_steps = 1  # 예시로 1로 설정했지만, 시퀀스 데이터의 길이에 맞게 조정 가능\n",
    "\n",
    "    # shape 재구성 (samples, time steps, features)\n",
    "    X_train = X_train.reshape(X_train.shape[0], time_steps, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], time_steps, X_test.shape[1])\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # 모델 구축\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model = compile_model(model)\n",
    "\n",
    "    # 모델 훈련\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # 모델 평가\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1552, 1, 24)\n",
      "X_test shape: (389, 1, 24)\n",
      "y_train shape: (1552, 7)\n",
      "y_test shape: (389, 7)\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 4s 26ms/step - loss: 1.7962 - accuracy: 0.4553 - val_loss: 1.5256 - val_accuracy: 0.5563\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.4251 - accuracy: 0.5052 - val_loss: 1.2293 - val_accuracy: 0.5691\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.1895 - accuracy: 0.5552 - val_loss: 1.0434 - val_accuracy: 0.6109\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.0231 - accuracy: 0.6180 - val_loss: 0.9216 - val_accuracy: 0.6559\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.9110 - accuracy: 0.6608 - val_loss: 0.8417 - val_accuracy: 0.7106\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.8347 - accuracy: 0.6978 - val_loss: 0.7886 - val_accuracy: 0.7170\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7794 - accuracy: 0.7083 - val_loss: 0.7557 - val_accuracy: 0.7170\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7410 - accuracy: 0.7244 - val_loss: 0.7333 - val_accuracy: 0.7235\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.7293 - val_loss: 0.7155 - val_accuracy: 0.7363\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.7429 - val_loss: 0.6937 - val_accuracy: 0.7331\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.7526 - val_loss: 0.6762 - val_accuracy: 0.7267\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6533 - accuracy: 0.7494 - val_loss: 0.6815 - val_accuracy: 0.7235\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.7599 - val_loss: 0.6674 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.7510 - val_loss: 0.6499 - val_accuracy: 0.7235\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6253 - accuracy: 0.7591 - val_loss: 0.6458 - val_accuracy: 0.7203\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.7583 - val_loss: 0.6471 - val_accuracy: 0.7299\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.7712 - val_loss: 0.6303 - val_accuracy: 0.7460\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.7712 - val_loss: 0.6320 - val_accuracy: 0.7395\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7712 - val_loss: 0.6243 - val_accuracy: 0.7524\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7808 - val_loss: 0.6152 - val_accuracy: 0.7556\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7824 - val_loss: 0.6247 - val_accuracy: 0.7428\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5469 - accuracy: 0.7857 - val_loss: 0.6052 - val_accuracy: 0.7653\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7816 - val_loss: 0.6162 - val_accuracy: 0.7428\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7816 - val_loss: 0.6062 - val_accuracy: 0.7492\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7937 - val_loss: 0.5960 - val_accuracy: 0.7492\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7824 - val_loss: 0.6134 - val_accuracy: 0.7428\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5189 - accuracy: 0.7994 - val_loss: 0.6068 - val_accuracy: 0.7556\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7832 - val_loss: 0.6036 - val_accuracy: 0.7556\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7913 - val_loss: 0.6016 - val_accuracy: 0.7556\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7969 - val_loss: 0.5907 - val_accuracy: 0.7588\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7985 - val_loss: 0.5953 - val_accuracy: 0.7621\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.8042 - val_loss: 0.6018 - val_accuracy: 0.7588\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.8082 - val_loss: 0.5969 - val_accuracy: 0.7653\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.8114 - val_loss: 0.5884 - val_accuracy: 0.7685\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.8098 - val_loss: 0.5900 - val_accuracy: 0.7621\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.8122 - val_loss: 0.6036 - val_accuracy: 0.7588\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.8018 - val_loss: 0.6075 - val_accuracy: 0.7556\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.8090 - val_loss: 0.6113 - val_accuracy: 0.7588\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.8098 - val_loss: 0.5999 - val_accuracy: 0.7685\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8219 - val_loss: 0.5971 - val_accuracy: 0.7717\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.8090 - val_loss: 0.6041 - val_accuracy: 0.7588\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8090 - val_loss: 0.5880 - val_accuracy: 0.7588\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8131 - val_loss: 0.6110 - val_accuracy: 0.7621\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8251 - val_loss: 0.5972 - val_accuracy: 0.7621\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8251 - val_loss: 0.6058 - val_accuracy: 0.7653\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.8195 - val_loss: 0.6030 - val_accuracy: 0.7653\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8340 - val_loss: 0.6033 - val_accuracy: 0.7524\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8284 - val_loss: 0.5937 - val_accuracy: 0.7556\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8340 - val_loss: 0.5945 - val_accuracy: 0.7685\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8300 - val_loss: 0.6008 - val_accuracy: 0.7717\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7712\n",
      "Test loss: 0.6409, Test accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 데이터 전처리\n",
    "    X_train, X_test, y_train, y_test, scaler = load_data(df_eda)\n",
    "\n",
    "    # time steps 설정\n",
    "    time_steps = 1  # 예시로 1로 설정했지만, 시퀀스 데이터의 길이에 맞게 조정 가능\n",
    "\n",
    "    # shape 재구성 (samples, time steps, features)\n",
    "    X_train = X_train.reshape(X_train.shape[0], time_steps, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], time_steps, X_test.shape[1])\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # 모델 구축\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model = compile_model(model)\n",
    "\n",
    "    # 모델 훈련\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # 모델 평가\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 3ms/step - loss: 1.9492 - accuracy: 0.1105\n",
      "Original Test loss: 1.9492, Original Test accuracy: 0.1105\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.7686\n",
      "After dropping column 1: Test loss: 0.6531, Test accuracy: 0.7686\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.7558\n",
      "After dropping column 2: Test loss: 0.6534, Test accuracy: 0.7558\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.7686\n",
      "After dropping column 3: Test loss: 0.6490, Test accuracy: 0.7686\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.7532\n",
      "After dropping column 4: Test loss: 0.6638, Test accuracy: 0.7532\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7532\n",
      "After dropping column 5: Test loss: 0.6714, Test accuracy: 0.7532\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.7841\n",
      "After dropping column 6: Test loss: 0.6398, Test accuracy: 0.7841\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7558\n",
      "After dropping column 7: Test loss: 0.6522, Test accuracy: 0.7558\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.7609\n",
      "After dropping column 8: Test loss: 0.6584, Test accuracy: 0.7609\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7661\n",
      "After dropping column 9: Test loss: 0.6714, Test accuracy: 0.7661\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7763\n",
      "After dropping column 10: Test loss: 0.6539, Test accuracy: 0.7763\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.7147\n",
      "After dropping column 11: Test loss: 0.7295, Test accuracy: 0.7147\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7558\n",
      "After dropping column 12: Test loss: 0.6576, Test accuracy: 0.7558\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.7661\n",
      "After dropping column 13: Test loss: 0.6822, Test accuracy: 0.7661\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.7326\n",
      "After dropping column 14: Test loss: 0.6958, Test accuracy: 0.7326\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7738\n",
      "After dropping column 15: Test loss: 0.6494, Test accuracy: 0.7738\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.7506\n",
      "After dropping column 16: Test loss: 0.6782, Test accuracy: 0.7506\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7532\n",
      "After dropping column 17: Test loss: 0.6781, Test accuracy: 0.7532\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7763\n",
      "After dropping column 18: Test loss: 0.6450, Test accuracy: 0.7763\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7661\n",
      "After dropping column 19: Test loss: 0.6609, Test accuracy: 0.7661\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7712\n",
      "After dropping column 20: Test loss: 0.6310, Test accuracy: 0.7712\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.7506\n",
      "After dropping column 21: Test loss: 0.6623, Test accuracy: 0.7506\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.7532\n",
      "After dropping column 22: Test loss: 0.6673, Test accuracy: 0.7532\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7635\n",
      "After dropping column 23: Test loss: 0.6910, Test accuracy: 0.7635\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.7686\n",
      "After dropping column 24: Test loss: 0.6502, Test accuracy: 0.7686\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7661\n",
      "After dropping column 25: Test loss: 0.6600, Test accuracy: 0.7661\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7635\n",
      "After dropping column 26: Test loss: 0.6647, Test accuracy: 0.7635\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7558\n",
      "After dropping column 27: Test loss: 0.6580, Test accuracy: 0.7558\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 데이터 전처리\n",
    "    X_train, X_test, y_train, y_test, scaler = load_data(df)\n",
    "\n",
    "    # time steps 설정\n",
    "    time_steps = 1  # 예시로 1로 설정했지만, 시퀀스 데이터의 길이에 맞게 조정 가능\n",
    "\n",
    "    # shape 재구성 (samples, time steps, features)\n",
    "    X_train = X_train.reshape(X_train.shape[0], time_steps, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], time_steps, X_test.shape[1])\n",
    "\n",
    "    # 모델 구축\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model = compile_model(model)\n",
    "\n",
    "    # 원래 모델 성능 평가\n",
    "    original_loss, original_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Original Test loss: {original_loss:.4f}, Original Test accuracy: {original_accuracy:.4f}')\n",
    "\n",
    "    # 컬럼을 하나씩 드랍하면서 모델 성능 테스트\n",
    "    for i in range(X_train.shape[2]):\n",
    "        # 원본 데이터에서 해당 컬럼을 제거하여 새로운 데이터 생성\n",
    "        X_train_temp = np.delete(X_train, i, axis=2)\n",
    "        X_test_temp = np.delete(X_test, i, axis=2)\n",
    "\n",
    "        # 모델 구축\n",
    "        input_shape_temp = (X_train_temp.shape[1], X_train_temp.shape[2])\n",
    "        model_temp = build_model(input_shape_temp)\n",
    "\n",
    "        # 모델 컴파일\n",
    "        model_temp = compile_model(model_temp)\n",
    "\n",
    "        # 모델 훈련\n",
    "        history_temp = model_temp.fit(X_train_temp, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "        # 모델 평가\n",
    "        loss_temp, accuracy_temp = model_temp.evaluate(X_test_temp, y_test)\n",
    "        print(f'After dropping column {i+1}: Test loss: {loss_temp:.4f}, Test accuracy: {accuracy_temp:.4f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec5_pj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
